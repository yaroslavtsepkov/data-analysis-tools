# Описание выполненной работы
В качестве исходных данных были взят котировки компании **Virgin Galactic** с результатами торгов с 03.03.2020 по 03.03.2021 с периодом в 1 день.
- Выполнены все пункты лабораторной работы

# Осписание лабораторной работы
# Лабораторная работа №2: Pandas

[Лекции](pandas-1.ipynb), [ч.2](pandas-2.ipynb)

1. Считать в pandas DataFrame любой источник данных: любой CSV, JSON, Excel-файл, HTML-таблицу, данные из любой СУБД куда у вас есть доступ и т.п.
Также можно сконвертировать в dataframe любой из встроенных датасетов sklearn: (см. [инструкцию](https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset))
Одним словом загружаете данные откуда угодно, куда можете дотянуться.
Главное условие к датасету, который вы загружаете — там должны быть числовые колонки (по сути численные признаки).

2. Совершаете с датафреймом следующие операции:
    1. `.head()`
    2. `.describe()`
    3. считайте значение конкретной ячейки (с конкретным индексом из конкретной колонки)
    4. фильтрация строк по диапазону индекса
    5. фильтрация набора данных по какому-либо условию
    6. работа с пропущенными значениями (если они есть): удаление строк с пропущенными значениями, заполнение пропущенных значений средним значением по колонке. Если пропущенных значений нет — намеренно их "генерируете", прибивая какие-то куски данных в np.nan
    7. создание нового поля вычисленного на основе значений других полей:
      1. через выражение на базе имеющихся колонок,
      2. через `DataFrame.apply`
      3. через `Series.apply`
    8. сортировка по какому-либо из полей
    9. вычислить несколько статистик по колонкам (используйте встроенные агрегатные функции — любые на выбор)
   10. По какому-либо полю / набору полей смотрим число значений с помощью `.value_counts()`
    11. Если значений немного — вывод уникальных значений какой-либо колонки через `.unique()`
    12. Удалите текущий индекс и создайте новый индекс на базе новой колонки, которая для этого лучше всего подходит

3. Продемонстрировать работу `.groupby`, на основе группировок в groupby вычисляете агрегатные функции по одной или нескольким колонкам

4. Решейпинг данных 1Dto2D с помощью `.pivot` (можно подать на вход результаты агрегатов, полученных ранее через `.groupby` (сгруппировать по двум полям), либо прекрасно заходит сюда данные из SQL сгруппированные предварительно по 2-м полям) 

5. Решейпинг 1Dto2D данных соединённый с группировкой / агрегацией (одним словом — сводная таблица): `.pivot_table`. Группируем только по категориальным полям или числовым, если уверены, что значений немного! Если значений много, можете вначале из загрубить (см. (2.7.) либо (7)) 

6. Посчитать квантили распределения какого-либо вещественного признака (с помощью `numpy.quantile` или `numpy.percentile`) 

7. Посчитать (в виде текста) гистограмму какого-либо вещественного признака (с помощью `numpy.histogram`). Значения гистограммы можете использовать как вариант в качестве загрубленного числового признака для заданий (4) или (5).

8. Получить `DataFrame` с `MultiIndex` любым способом: через конструктор (в документации увидите множество видов конструкторов для создания MultiIndex с нуля), через `read_sql` / `read_csv` / `read_excel`, `read_*`, через `pivot_table`, через `groupby` или иными способами.
    1. Переставить местами уровни индекса
    2. Транспонировать таблицу (или создать новую другую) с MultiIndex
    3. Удалить один из уровней индекса или добавить новый уровень индекса (можно инициализированный константой) — посмотрите сами в документации как это делать

9. Продемонстировать работу `.merge`
10. Продемонстрировать работу с `.concat` или `append`
11. Проитерировать dataframe построчно `.iterrows()` и что-то "полезное" сделайте внутри цикла


### Замечания:

Некоторые используют `.pivot` и `.pivot_table` неправильно, в неподходящем контексте, в результате получается бессмыслица.

`.pivot` нужен для того, чтобы результаты двухуровневой группировки представить в виде двумерной таблицы, где один из уровней группировки уходит в строчки, другой в столбцы.

`.pivot_table` нужен для того же, только умеет сам группировать / агрегировать данные, в не просто растаскивать ячейки по двумерной таблице.
